%----------------------------------------------------------------------------
\chapter{Elméleti áttekintés}
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
\section{Paralell rendszerek}
%----------------------------------------------------------------------------

A félvezető alapú processzorok tranzisztorszáma hozzávetőlegesen megjelenésük óta \cite{Moore} törvényének megfelelően minden két évben megduplázódik. Az exponenciális növekedés lehetővé teszi a processzorok órajelének felskálázását, nagyobb memóriák előállítását, sőt, még a digitális kamerák szenzorainak pixelméretét is érinti. A jelenlegi tranzisztor koncepció és gyártástechnológia nem enged meg atomi méretnél kisebb tranzisztorokat, így a hagyományos tranzisztorok exponenciális növekedésben idővel letörés várható, azonban a processzorok órajelének növekedését már most egy sokkal súlyosabb akadály hátráltatja: a rengeteg, kis helyre zsúfolt félvezető eszköz hőterhelése olyan nagy, hogy az eszköz önmagát megrongálja. A jelenség miatt a processzor órajel növekedés mértéke a 2000-es évek elején csökkenésnek indult \cite{CMOS-VLSI}. A technikai fejlődés folytonossága érdekében a félvezetőgyártók -- a tranzisztorok zsúfoltságát csillapítandó -- egy processzorba több végrehajtó egységet (\emph{magot}) kezdek integrálni, melyek párhuzamosan dolgozva képesek egységnyi idő alatt több utasítást végrehajtani, a hőterhelés túlzott koncentrálása nélkül, ezzel megnyitva egy új korszakot a modern szoftverfejlesztésben.

    A többmagos rendszerek megjelenése egy sor új lehetőséget és kihívást állít a szoftverfejlesztők elé, akik ki akarják használni a konkurens rendszerek képességeit, azaz több szálat, folyamatot kívánnak párhuzamosan utilizálni. A piaci lehetőség elsősorban abban rejlik, hogy az a szoftver, ami képes elosztottan működni, és így teljesítménye a végrehajtóegységek számának növekedésével jól skálázódik, szignifikánsan hatékonyabb, mint azok, amik nem képesek erre. Az ebben az értelemben hatékony rendszerek fejlesztési költségeinek megnövekedését a konkurens rendszerek természetéből fakadók kihívások okozzák. (Megjegyzendő, hogy a többszálú alkalmazások megjelenése megelőzte a többmagos processzorok elterjedését, utóbbi csak növelte a konkurens természet jelentőségét.)
    
    % nem determinisztikussag 
    Az egyik legfontosabb különbség, amivel a programozó egy konkruens rendszer fejlesztése során szembesül, hogy az utasítások végrehajtásának sorrendje nem determinisztikus a többszálúság végett. Ennek következtében nem elég a program működésével \emph{nagyjából} tisztában lenni, nem lehet néhány tesztesetet lefuttatva megbizonyosodni a funkcionalitás helyességéről: bármikor előfordulhat, hogy a teszteset futtatásakor éppen kedvező volt a szálak ütemezése, és így a végeredmény értelmében helyes működés volt megfigyelhető, azonban a program hibás, más ütemezés, időzítés esetén viszont ennek megfelelően hibás eredményre fog jutni. A párhuzamosan futó szálak helyes működésének biztosítását és a szinkronizációs lehetőségeket az \ref{sec:communication_of_parallel_systems} szakasz tárgyalja.
    
    % parhuzamosithato reszek felderitese, 
    Az előbbi, leginkább technikai nehézségen megoldandó problémát jelent egy program komponenseinek párhuzamosítása. A fejlesztőnek azonosítania kell azokat a részeket, amelyek képesek egymástól függetlenül működni, nem támaszkodnak a másik eredményeire, így az egyes tevékenységek külön szálakon végezhetőek, akár egy időben is. Az ilyen egyszerű módon párhuzamosítható feladatokat nevezzük triviálisan párhuzamosíthatónak. Triviálisan párhuzamosítható algoritmus a mátrixszorzás algoritmusa: $\bm A \cdot \bm B = \bm C$ esetén $\bm C_{i, j}$ értéke csak $\bm A_i$ és $\bm B_j$ függvénye. A jól párhuzamosítható algoritmusok fejlesztése aktív kutatási terület.
    
    Más esetekben előfordulhat, hogy két komponens függ egymástól, működésük mégis átlapolható: ha $B$ feladat $i+1.$ iterációja csak $A$ feladat $i.$ iterációjától függ, a két feladat $i+1.$ iterációja futhat párhuzamosan. Egy ilyen típusú feladatra példa lehet egy olyan rendszer, ami szövegfájlokat dolgoz fel és az eredményeit egy adatbázisba írja. A fenti definíciónál maradva itt $A$-val jelölhetjük a fájl egy nagyobb részének beolvasását és feldolgozását, míg $B$-vel az adatbázis írását. Amíg $A$ olvassa a fájlt és a lemezművelet miatt blokkolódik, $B$ kiírhatja az előző számítás eredményeit, fordítva pedig amikor $B$ az adatbázisművelet befejezésére vár, $A$ olvashatja és feldolgozhatja a bemeneti fájl következő darabját. Az ilyen típusú szétcsatolások felderítése és kiaknázása jelenti a szoftverek párhuzamosításának elsődleges célpontját.
    
    Léteznek továbbá olyan algoritmikus problémák, amelyek szándékosan úgy lettek megalkotva, hogy ne lehessen őket disztributálni. A \cite{bcrypt} kriptográfiai algoritmus a bemenetén specifikált értékkel arányosan sok iterációt végez, továbbá minden egyes iteráció támaszkodik az előző eredményére. Ebben az esetben a motiváció az elosztott és párhuzamos rendszerek által végzett kódtörés elleni védelem elősegítése.
    
    % Itanium
    Felmerül a kérdés, hogyha a teljesítménynövekedés ennyire egyértelmű, miért nem végzi el a párhuzamosítható részek keresését a fordító program vagy a processzor, ahogy teszik azt számos más optimalizáció esetében. Mivel a processzor nem ismerheti a végrehajtandó utasítások szemantikáját, magas szintű párhuzamosíthatóság felderítésére aligha van lehetőség. Ellenben a fordítóprogram által párhuzamosított program végrehajtását támogató utasításkészletek léteznek, például a \cite{VLIW}, vagy az Intel Itanium processzorcsalád alapja, az \cite{EPIC}. Az ilyen architektúrájú processzorok lényegében több párhuzamos csővezetékkel (\emph{pipeline}) rendelkeznek, melyekben képesek párhuzamos utasításvégrehajtásra. A megközelítés hátránya, hogy a hatékony működéshez megfelelő heurisztikákat alkalmazó fordítókra lenne szükség, azonban ezek a mai napig kutatás tárgyát képezik.
    
    A párhuzamosított programokat futtatni képes konkurens rendszerek sem jelentenek tetszőleges mértékben skálázható teljesítménynövekedést. \cite{Amdahl} törvénye kimondja, hogyha a programunknak csupán $B$ hányada nem párhuzamosítható (márpedig ilyen hányad napjaink programjainak természetéből fakadóan mindig akad, pl.: futtatókörnyezet inicializáció, felhasználói interakcióra várakozás, adatbázis és hálózati műveletek, stb.), és ezt a programot egy $n$ szálat párhuzamosan futtatni képes processzoron futtatjuk, akkor a végrehajtáshoz szükséges idő arányos lesz $T(n)$-nel:
    
    \begin{equation}
        T(n) = T(1)\big(B+\frac{1}{n}(1-B)\big)
    \medskip
    \end{equation}
%    
    Ebből következően az elméleti sebességnövekedés adott rendszeren $S(n)$:
    
    \begin{equation} \label{eq:amdahl}
        S(n) = \frac{T(1)}{T(n)} = \frac{1}{B+\frac{1}{n}(1-B)}
    \medskip
    \end{equation}
%
%   \eqref{eq:amdahl} fails to ref for some reason.
    Az $(1.2)$ egyenletbe $B = 0.05$ értéket helyettesítve $\lim\limits_{n \rightarrow \infty}{S(n)}$ értéke $20$-nak adódik, avagy ha programunknak csak $5\%$-a nem párhuzamosítható, hiába futtatjuk a fennmaradó részét akár végtelen sok feldolgozó egységgel rendelkező architektúrán, csupán hússzoros teljesítménynövekedést érhetünk el.

    \subsection{Paralell rendszerek kommunikációja \textcolor{red}{TODO}} \label{sec:communication_of_parallel_systems} 
        Többszálú, elosztott rendszerek. Locking, lock-free structures, token based shared data.
    \subsection{Rendszer holtpontja} 
      
    A következőkben tekinktsünk egy rendszerre, mint különböző feladatokat végrehajtó ágensek halmazára. Egy ágens eseményekre vár és bizonyos események hatására műveleteket végez, majd eseményeket vált ki. Ekkor egy rendszer valamely $H$ részhalmaza holtponton van akkor, ha $H$ minden eleme olyan eseményre vár, amit csak $H$ egy másik eleme tud kiváltani. Ha a rendszer bármely részhalmaza holtpontra jut, az adott rész működése leáll, gyakran magával vonva a teljes rendszer használhatatlanná válását. A fenti definícióra egy szemléletes példa a \cite{DiningPhilosophers} probléma, mely röviden a következő képpen vázolható: Egy terített asztal körül filozófusok ülnek. A teríték különlegessége, hogy mindegyikük között csak pontosan egy evőeszköz található, azonban az étkezés megkezdéséhez két evőeszközre van szükségük. Ekkor ha mindegyikük először a jobb oldali evőeszközt veszi kézbe, a bal oldali felvétele előtt várakozásra kényszerül, mivel az bal szomszédjának jobb oldali evőeszköze volt, tehát éppen használatban van. Így kölcsönös egymásra várás alakul ki, tehát az étkezőasztal, mint rendszer, holtpontra jut.
    
    Holtpont előfordulhat a tárgyalt paralell rendszerek esetében is. Ekkor a rendszer (az étkezőasztal) egy futó folyamat, a végrehajtó ágensek (a filozófusok) pedig a folyamat szálai. A definíció és a továbbiakban tárgyalt problémak és megoldások ugyanígy kiterjeszthetőek nagyobb léptékű problémákra is, például elosztott rendszerekre, ahol a rendszer a teljes fürtnek, a végrehajtó ágensek pedig az egyes fürtbe kapcsolt számítógépeknek felelnek meg.
    
    Egy szoftverrendszer számára a holtpont nem szükségszerűen okoz hibás kimenetet, többnyire inkább a kimenet hiánya az elsődleges tünet, ami a működés lebénulását jelenti, anélkül, hogy a holtpontra jutott folyamat terminálna, ezáltal jelezve a hibát az esetleges felügyeleti rendszereknek.
    
    Egy rendszer holtpontmentességének bizonyítása pusztán tesztesetek ismételt futtatásával nem lehetséges. Mivel holtpontot okozhat időzítési probléma (\emph{versenyhelyzet}), gyakran előfordul, hogy fejlesztés közben -- például a hiányzó fordítási idejű optimalizációk miatt -- a probléma nem jelentkezik. Ugyanígy befolyásolhatja az egyes szálak ütemezését, és így a holtpont kialakulásának lehetőségét, egy (az éles környezettől különböző) tesztkörnyezet, a valóditól eltérő tesztadat, vagy pusztán mérési zaj. Ennek ellenére minden erőfeszítést meg kell tenni, hogy a lehetséges problémák még az üzemi környezetbe helyezés előtt kiderüljenek. Egy olyan környezetben, ahol nem áll rendelkezésünkre elegendő hibakeresési eszköz (pl.: \emph{debug szimbólumok}, kimerítő naplóbejegyzések) vagy maga a futó folyamat (csak \emph{post-mortem} vizsgálat lehetséges), ott bekövetkezett holtpont felderítése különösen nehéz.
    
    Adódik a kérdés, hogy hogyan védekezzünk a holtpontok ellen, hogyan elimináljuk a vizsgálat során a nemdeterminisztikusságból adódó bizonytalanságot, milyen technikák léteznek holtpontmentes rendszer kialakítására, valamint hogyan tegyük a rendszerünket ellenállóvá, ha holtpont előfordulhat. A következőkben tárgyalásra kerülnek különböző holtpont megelőzési (\ref{sec:dl-prevention}. szakasz) és holtpont elkerülési (\ref{sec:dl-avoiding}. szakasz) technikák, valamint a \ref{sec:dlhunter}. fejezet bemutat egy ezektől eltérő felderítési technikát alkalmazó eszközt.

%----------------------------------------------------------------------------
\section{Holtpontmegelőzés a gyakorlatban  \textcolor{red}{TODO}} 
\label{sec:dl-prevention}
Néhány megelőzési technika bemutatása, hogy később világosan látszódjon, esetünkben miért nem használhattuk ezeket.

    Holtpont kialakulásának szükséges feltételei a következőek:
    
    \begin{description}
    \item[Kölcsönös kizárás:] Egyes erőforrásokat egyszerre csak korlátozott számú ágens használhat. Példánkban egy evőeszközt egyszerre csak egy filozófus vehet kézbe.
    \item[Foglalva várakozás:] Egy ágens várakozhat úgy erőforrásra, hogy közben más erőforrást már zárolt. Példánkban egy filozófus várakozhat evőeszközre, miközben már rendelkezik eggyel.
    \item[Erőforráselvétel hiánya:] Egy ágens nem foszthat meg egy másikat erőforrásaitól. Példánkban a filozófusok nem vehetik ki egymás kezéből az evőeszközöket.
    \end{description}
    
    \textcolor{red}{TODO} % TODO
    % korkoros varakozas, mint feltetel?
    % szukseges feltetelek, mind egyszerre kell
    % egyiket elvesszuk, jo lesz -> melyik szakaszban targyaljuk? szakasz igazitasa e szerint
%----------------------------------------------------------------------------

    \subsection{Hierarchikus zárolás} 
    A holtpont definíciót megvizsgálva láthatjuk, hogy holtpont akkor fordulhat elő, ha az egyik végrehajtó egység lefoglalt egy erőforráshalmazt, majd ezután egy másikat szeretne kisajátítani, miközben azt már egy másik végrehajtó egység lefoglalta, ami az előbbi halmaz egy elemére vár. Ez megegyezik azzal az esettel, ha a szálak a kérdéses erőforrások halmazának bármely két elemét \emph{különböző sorrendben} zárolnák. A felismerés alapján adódik a hierarchikus zárolás technikájának ötlete: Definiáljunk az erőforrások halmazán egy teljes rendezést. A szálak csak a definiált sorrend szerint növekvő sorrendben zárolhatják az egyes entitásokat, a holtpont kialakulását elkerülendő. 
    
    Ha sikerül a két feltételt betartani, biztosak lehetünk abban, hogy a vizsgált erőforrásokat használó szálak között nem fog holtpont kialakulni. Az entitások rendezéséhez célszerű lenne, ha mindegyikhez egy számértéket rendelnénk, ami alapján egyértelműen adódna a sorrend. Ha a memóriacímet használjuk erre a célra, matematikai értelemben megfelelő rendezést kapunk, azonban ez a sorrend fordításról fordításra (különböző architektúrákon, operációs rendszereken, eltérő fordító kapcsolók esetén vagy pusztán a kód megváltoztatása miatt), valamint futtatásról futtatásra változhat (ASLR\footnote{http://en.wikipedia.org/wiki/Address\_space\_layout\_randomization}-t használó futtatókörnyezet esetén vagy ha a memória nincs virtualizálva). A memóriacím változó jellege miatt nagyon körülményes visszakozó megoldásokat kell alkalmazni az erőforrások zárolása során, melyek erőforráspazarlóak (a sorozatos visszalépések és újrapróbálkozások miatt) vagy nagyon bonyolult struktúrákhoz vezetnek (előre meg kell határozni az erőforrások lefoglalásának sorrendjét és ehez igazítani a műveletek sorrendjét is) melyek rendszerint nem is alkalmazhatóak és karbantartásuk nagyon költséges.
    
    Memóriacímek helyett adjunk manuálisan sorszámot az egyes erőforrásoknak. Ez rendszerint egy tagváltozó beállításával történik, de bizonyos szigorú követelmények mellett (zárak csak globális változók vagy amennyiben tagváltozók, a befoglaló osztályból csak egy példány lehet, mindegyik egy fordítási egységben vagy fájlban van definiálva) használhatunk preprocesszor makrókat, pl.: \texttt{\_\_LINE\_\_} vagy \mbox{BOOST\_PP\_COUNTER()}\footnote{http://www.boost.org/doc/libs/1\_54\_0/libs/preprocessor/doc/ref/counter.html}. A \cite{C++11/Lockable} modellt kiterjesztő beszámozható erőforrásburkoló a következőképpen nézhet ki:
    
    \includecpp{hierarchical-locking}{6}{36}
    
    A fenti példa két problémára is megoldást nyújt: lehetőséget ad az egyes entitások beszámozására az inicializáláskor, valamint biztosítja azt, hogy az egyes szálak csak a legutóbb zárolt de még nem elengedett erőforrás azonosítójánál nagyobb azonosítójú erőforrást zárolhassanak. Az ellenőrző rutin által dobott kivételt nem ajánlott elkapni, a hibát kiváltó szál működését kell a kialakított sorrendhez alakítani. Az ellenőrzés helyes működéséhez szükség van egy szálspecifikus tárolóban elhelyezett veremre, ami a foglalások sorrendjét jegyzi. Fontos megjegyezni, hogy a \texttt{thread\_local} tárolási osztály leíró (\emph{Storage class specifier}) és a benne tárolt nem \cite{C++11/POD}-típusú elemek jelenleg gyengén támogatottak, így egyes platformokon (pl.: GCC version < 4.8) szükséges lehet \texttt{thread\_local} helyett a \texttt{\_\_thread} leíró használata, vagy a verem helyett csak egy veremre mutató pointer tárolása, amit az egyes szálak indításakor inicializálni kell.
    
    A megoldás hátránya, hogy az egyes erőforrásokat már tervezési időben rendezni kell (legalább valamilyen fa struktúrába), hogy az egyes szálak működése ennek megfelelően legyen kialakítva. Ha a sorrend meghatározása a fejlesztés megfelelően korai fázisában elmarad, később csak komoly erőfeszítések árán pótolható, mivel az egyes szálak működésének megváltoztatását vonhatja maga után. 
    
    A másik probléma egy elemenként zárolható listával modellezhető. Tegyük fel, hogy az egyik algoritmusunk a listát balról jobbra tudja hatékonyan feldolgozni, az egyedi elemeket folyamatosan, egymás után zárolva, de nem elengedve, míg egy másik algoritmus ugyan ezt tudja, csak jobbról balra. Ha az elemekhez rendelt zárakat a nekik megfelelő sorban szeretnénk lefoglalni, az egyik algoritmus úgy kell megváltoztatni, hogy az az összes elemet egyszerre (vagy legalábbis igényeihez képest ellentétes irányban) zárolja, ami rontja a hatékonyságát. Ha nem szeretnénk egyik algoritmust sem megváltoztatni, használhatunk egy lista szintű zárat, ez viszont csökkenti a zárolás granualitását, ami adott esetben kritikus lehet.
    
    Az elemenként zárolható lista példája életszerűtlennek tűnhet, viszont az ezzel modellezhető problémák (pl.: üzenet propagálása egy architektúra rétegein keresztül) nagyonis életszerűek.
    
    A hierarchikus zárolás technika alkalmazása olyan feladatokban, ahol az adatfolyam iránya egyértelmű, sikerrel használható, de különös körültekintést és alapos tervezést igényel, ellenben a fent bemutatott példának a futásidejű többletterhelése nem szignifikáns. Ezzel szemben már létező, karbantartandó, a technikát nem alkalmazó problémás alkalmazások ilyen módú kijavítása ritkán vezet eredményre és komoy erőfeszítést igényel. Olyan feladatok esetén, ahol az egyes komponensek kommunikációjának iránya nem egyértelmű, a technika nem alkalmazható jelentős teljesítménybeli degradáció nélkül.
    
    \subsection{Egylépéses zárolás}
    
    A holtpont megelőzhető úgy, ha minden szál a szükséges erőforrásokat egy lépésben foglalja le. Ennek menete a következő: A szál meghatározza a zárolandó entitásokat, majd sorban megpróbálja őket lefoglalni. Amennyiben valamelyik erőforrás foglalt, az összes többit elengedi, majd várakozni kezd a foglalt entitásra. A C++11 \texttt{std::lock()} metódusa is ezt a működést valósítja meg \cite{C++11/lock}:
    
    \includecpp{stdlock}{11}{19}
%    
    A fenti megoldás hibája, ha a {lock()} hívás után bármelyik művelet kivételt eredményez, a mutexek zárva maradnak. Java vagy C\texttt{\#} környezetben bevett szokás a probléma megoldására egy \texttt{try-finally} blokkot vonni a védett operációk köré, és a \texttt{finally} blokkban végezni az erőforrások felszabadítását. C++ esetében a preferált megoldás a \texttt{RAII} idiom \cite{ExceptionalC++} alkalmazása.
    
    \includecpp{stdlock}{23}{31}
%    
    A \texttt{lock\_guard} burkoló osztályok gondoskodnak arról, hogy megsemmisülésükkor elengedjék a felügyelt mutexet. Mivel kivétel keletkezése esetén a vezérlés elhagyja a kapcsos zárójelek által határolt blokkot, meghívódik az őr példányok destruktora és a fenti működés érvényre jut, biztosítva ezzel az inkonzisztens állapot kialakulásának megakadályozását. A \texttt{lock\_guard} konstruktora alapértelmezett esetben megpróbálja a felügyelt erőforrást zárolni, a \texttt{std::adopt\_lock} címke feltüntetésével jelezzük, hogy erre már nincs szükség.
    
    Megjegyzendő, hogy a fenti technikák nem csak a standard könyvtár mutex típusával működnek, hanem bármilyen más típussal, ami kielégíti a \texttt{Lockable} modell követelményeit \cite{C++11/Lockable}. A megvalósítandó metódusok rövid leírásukkal a következőek:
    
\begin{description}
    \item[\texttt{lock()}:] Blokkol addig, amíg nem tudja zárolni az erőforrást. Amennyiben kivétel keletkezik, az erőforrás nem marad zárolva.
    \item[\texttt{unlock()}:] Felszabadítja az erőforrást, kivételt nem válthat ki.
    \item[\texttt{try\_lock()}:] Blokkolás nélkül megkísérli zárolni az erőforrást, a sikerességet visszatérési értékével jelzi.
\end{description}
%
    A fentiek figyelembe vételével könnyen készíthetünk olyan burkoló osztályokat, amelyek a standard könyvtár zárolást támogató eszközeivel együttműködve használható és olyan erőforrásokat felügyel, amelyek alapértelmezetten nem támogatják a párhuzamos hozzáférést (pl.: adatbázis-kapcsolat, hálózati leíró).
    
    A bemutatott megoldás megelőzi a holtpontot kialakulását, mivel a \texttt{std::lock()} hívást végrehajtó szál ahelyett, hogy más erőforrásokat zárolva tartva várakozna, a sikeresen kisajátított zárakat először elengedi, és utána kezdi meg a várakozást, így nem alakulhat ki egymásra várás, mivel ha valaki várakozik, akkor nem birtokol erőforrásokat.
    
    Holtpont helyett viszont más problémák merülnek fel: a leírt visszakozás, \emph{backoff} stratégia alkalmazása során fenyeget a \emph{livelock} kialakulásának veszélye: a végrehajtó egységek nagyon udvariasan újra és újra elengedik a már lefoglalt erőforrásokat, érdemi előrelépés nélkül. A gyorsan ismétlődő visszakozásokból adódóan a \emph{livelock} szituációk súlyosan degradálják a rendszer teljesítményét.
    
    A megoldás másik hátránya a zárolási granualitás problémája. Ha több, egymásra épülő műveletet szeretnénk végrehajtani, hagyományos esetben a későbbi műveletek által igényelt erőforrások kisajátítását későbbre halaszthatjuk, így növelve a multiprogramozás fokát és a rendszer teljesítményét. Egylépéses zárolás esetén kénytelenek vagyunk minden entitást előre lefoglalni, így feleslegesen hosszú időre (túl korán) kisajátítani azokat, kizárva annak a lehetőségét, hogy más szálak azokon műveleteket végezhessenek, amikor ezt a végrehajtott műveletsor nem indokolja. Különösen rossz a helyzet akkor, ha (egy másik foglalás mellett) zárolható entitások listáján kell műveletet végeznünk: ahelyett, hogy csak az aktuális elemet sajátítanánk ki, kénytelenek vagyunk a teljes lista összes elemét zárolnunk, feleslegessé téve ezzel az elemszintű mutexeket, a konkurencia szintjét gyakorlatilag nullára csökkentve.
    
    További problémája a technikának, ha a lefoglalandó erőforrások egy részét csak futási időben ismerjük meg, egy másik zárolandó entitással történő interakció után. Ilyenkor csak nagyon körülményesen, vagy akár (csak futásidőben ismert számú erőforrás esetén) sehogyan sem tudjuk alkalmazni a megoldást.
    
    Az egylépéses zárolás megfelelő lehet kisebb alkalmazások holtpontmentességének biztosítására, nagyobb rendszerek esetén azonban a teljesítményt komoly mértékben negatívan befolyásoló jellege miatt nem megfelelő eszköz.
    
    \subsection{Lock-free adatstruktúrák \textcolor{red}{TODO}} AFAIK aktív kutatási terület, akár egy fél doktorit is lehetne ide írni.
    \subsection{Token alapú adathozzáférés \textcolor{red}{TODO}} Shared data atomic pointere swappelődik a threadek között.

%----------------------------------------------------------------------------
\section{Holtpontdetektálás a gyakorlatban \textcolor{red}{TODO}} 
\label{sec:dl-avoiding}
Ha megelőzni nem tudtuk, hogyan gyomláljuk ki
%----------------------------------------------------------------------------
    \subsection{Tünetvizsgálat \textcolor{red}{TODO}} CPU usage, progress monitorozása
    \subsection{Intel® Parallel Studio XE 2013 \textcolor{red}{TODO}} http://software.intel.com/en-us/intel-parallel-inspector Sajnos nincs trial, nem világos, hogy pontosan mit csinál a háttérben
