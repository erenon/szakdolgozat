%----------------------------------------------------------------------------
\chapter{Elméleti áttekintés}
%----------------------------------------------------------------------------

%----------------------------------------------------------------------------
\section{Paralell rendszerek}
%----------------------------------------------------------------------------

A félvezető alapú processzorok tranzisztorszáma hozzávetőlegesen megjelenésük óta \cite{Moore} törvényének megfelelően minden két évben megduplázódik. Az exponenciális növekedés lehetővé teszi a processzorok órajelének felskálázását, nagyobb memóriák előállítását, sőt, még a digitális kamerák szenzorainak pixelméretét is érinti. A jelenlegi tranzisztor koncepció és gyártástechnológia nem enged meg atomi méretnél kisebb tranzisztorokat, így a hagyományos tranzisztorok exponenciális növekedésben idővel letörés várható, azonban a processzorok órajelének növekedését már most egy sokkal súlyosabb akadály hátráltatja: a rengeteg, kis helyre zsúfolt félvezető eszköz hőterhelése olyan nagy, hogy az eszköz önmagát megrongálja. A jelenség miatt a processzor órajel növekedés mértéke a 2000-es évek elején csökkenésnek indult \cite{CMOS-VLSI}. A technikai fejlődés folytonossága érdekében a félvezetőgyártók -- a tranzisztorok zsúfoltságát csillapítandó -- egy processzorba több végrehajtó egységet (\emph{magot}) kezdek integrálni, melyek párhuzamosan dolgozva képesek egységnyi idő alatt több utasítást végrehajtani, a hőterhelés túlzott koncentrálása nélkül, ezzel megnyitva egy új korszakot a modern szoftverfejlesztésben.

    A többmagos rendszerek megjelenése egy sor új lehetőséget és kihívást állít a szoftverfejlesztők elé, akik ki akarják használni a konkurens rendszerek képességeit, azaz több szálat, folyamatot kívánnak párhuzamosan utilizálni. A piaci lehetőség elsősorban abban rejlik, hogy az a szoftver, ami képes elosztottan működni, és így teljesítménye a végrehajtóegységek számának növekedésével jól skálázódik, szignifikánsan hatékonyabb, mint azok, amik nem képesek erre. Az ebben az értelemben hatékony rendszerek fejlesztési költségeinek megnövekedését a konkurens rendszerek természetéből fakadók kihívások okozzák. (Megjegyzendő, hogy a többszálú alkalmazások megjelenése megelőzte a többmagos processzorok elterjedését, utóbbi csak növelte a konkurens természet jelentőségét.)
    
    % nem determinisztikussag 
    Az egyik legfontosabb különbség, amivel a programozó egy konkruens rendszer fejlesztése során szembesül, hogy az utasítások végrehajtásának sorrendje nem determinisztikus a többszálúság végett. Ennek következtében nem elég a program működésével \emph{nagyjából} tisztában lenni, nem lehet néhány tesztesetet lefuttatva megbizonyosodni a funkcionalitás helyességéről: bármikor előfordulhat, hogy a teszteset futtatásakor éppen kedvező volt a szálak ütemezése, és így a végeredmény értelmében helyes működés volt megfigyelhető, azonban a program hibás, más ütemezés, időzítés esetén viszont ennek megfelelően hibás eredményre fog jutni. A párhuzamosan futó szálak helyes működésének biztosítását és a szinkronizációs lehetőségeket az \ref{sec:communication_of_parallel_systems} szakasz tárgyalja.
    
    % parhuzamosithato reszek felderitese, 
    Az előbbi, leginkább technikai nehézségen megoldandó problémát jelent egy program komponenseinek párhuzamosítása. A fejlesztőnek azonosítania kell azokat a részeket, amelyek képesek egymástól függetlenül működni, nem támaszkodnak a másik eredményeire, így az egyes tevékenységek külön szálakon végezhetőek, akár egy időben is. Az ilyen egyszerű módon párhuzamosítható feladatokat nevezzük triviálisan párhuzamosíthatónak. Triviálisan párhuzamosítható algoritmus a mátrixszorzás algoritmusa: $\bm A \cdot \bm B = \bm C$ esetén $\bm C_{i, j}$ értéke csak $\bm A_i$ és $\bm B_j$ függvénye. A jól párhuzamosítható algoritmusok fejlesztése aktív kutatási terület.
    
    Más esetekben előfordulhat, hogy két komponens függ egymástól, működésük mégis átlapolható: ha $B$ feladat $i+1.$ iterációja csak $A$ feladat $i.$ iterációjától függ, a két feladat $i+1.$ iterációja futhat párhuzamosan. Egy ilyen típusú feladatra példa lehet egy olyan rendszer, ami szövegfájlokat dolgoz fel és az eredményeit egy adatbázisba írja. A fenti definíciónál maradva itt $A$-val jelölhetjük a fájl egy nagyobb részének beolvasását és feldolgozását, míg $B$-vel az adatbázis írását. Amíg $A$ olvassa a fájlt és a lemezművelet miatt blokkolódik, $B$ kiírhatja az előző számítás eredményeit, fordítva pedig amikor $B$ az adatbázisművelet befejezésére vár, $A$ olvashatja és feldolgozhatja a bemeneti fájl következő darabját. Az ilyen típusú szétcsatolások felderítése és kiaknázása jelenti a szoftverek párhuzamosításának elsődleges célpontját.
    
    Léteznek továbbá olyan algoritmikus problémák, amelyek szándékosan úgy lettek megalkotva, hogy ne lehessen őket disztributálni. A \cite{bcrypt} kriptográfiai algoritmus a bemenetén specifikált értékkel arányosan sok iterációt végez, továbbá minden egyes iteráció támaszkodik az előző eredményére. Ebben az esetben a motiváció az elosztott és párhuzamos rendszerek által végzett kódtörés elleni védelem elősegítése.
    
    % Itanium
    Felmerül a kérdés, hogyha a teljesítménynövekedés ennyire egyértelmű, miért nem végzi el a párhuzamosítható részek keresését a fordító program vagy a processzor, ahogy teszik azt számos más optimalizáció esetében. Mivel a processzor nem ismerheti a végrehajtandó utasítások szemantikáját, magas szintű párhuzamosíthatóság felderítésére aligha van lehetőség. Ellenben a fordítóprogram által párhuzamosított program végrehajtását támogató utasításkészletek léteznek, például a \cite{VLIW}, vagy az Intel Itanium processzorcsalád alapja, az \cite{EPIC}. Az ilyen architektúrájú processzorok lényegében több párhuzamos csővezetékkel (\emph{pipeline}) rendelkeznek, melyekben képesek párhuzamos utasításvégrehajtásra. A megközelítés hátránya, hogy a hatékony működéshez megfelelő heurisztikákat alkalmazó fordítókra lenne szükség, azonban ezek a mai napig kutatás tárgyát képezik.
    
    A párhuzamosított programokat futtatni képes konkurens rendszerek sem jelentenek tetszőleges mértékben skálázható teljesítménynövekedést. \cite{Amdahl} törvénye kimondja, hogyha a programunknak csupán $B$ hányada nem párhuzamosítható (márpedig ilyen hányad napjaink programjainak természetéből fakadóan mindig akad, pl.: futtatókörnyezet inicializáció, felhasználói interakcióra várakozás, adatbázis és hálózati műveletek, stb.), és ezt a programot egy $n$ szálat párhuzamosan futtatni képes processzoron futtatjuk, akkor a végrehajtáshoz szükséges idő arányos lesz $T(n)$-nel:
    
    \begin{equation}
        T(n) = T(1)\big(B+\frac{1}{n}(1-B)\big)
    \medskip
    \end{equation}
%    
    Ebből következően az elméleti sebességnövekedés adott rendszeren $S(n)$:
    
    \begin{equation} \label{eq:amdahl}
        S(n) = \frac{T(1)}{T(n)} = \frac{1}{B+\frac{1}{n}(1-B)}
    \medskip
    \end{equation}
%
%   \eqref{eq:amdahl} fails to ref for some reason.
    Az $(1.2)$ egyenletbe $B = 0.05$ értéket helyettesítve $\lim\limits_{n \rightarrow \infty}{S(n)}$ értéke $20$-nak adódik, avagy ha programunknak csak $5\%$-a nem párhuzamosítható, hiába futtatjuk a fennmaradó részét akár végtelen sok feldolgozó egységgel rendelkező architektúrán, csupán hússzoros teljesítménynövekedést érhetünk el.

    \subsection{Paralell rendszerek kommunikációja} 
    \label{sec:communication_of_parallel_systems} 
        
    Egy elosztott, konkurens rendszerben szükség lehet az egyes ágensek között információcsere biztosítására. Például a korábban említett átlapolt esetben a beolvasást és feldolgozást végző ágensnek értesíteni kell az adatbázisműveleteket végzőt, hogy a következő szelet processzálása megtörtént, az kész az adatbáziba írásra. Ekkor az eredményközlést és a kérdéses adat átadását úgy kell megvalósítani, hogy a jelzési folyamat során egyik ágens se érzékelhessen inkonzisztens állapotot a rendszerben -- a változtatásokat atomi módon kell végrehajtani.
        
    Máskor több ágens írhatja és olvashatja ugyan azt a fájlt (vagy más erőforrást), ekkor meg kell oldani a kérések sorosítását, mivel valódi párhuzamos hozzáférés esetén a fájl tartalma korrumpálódhatna -- az ágensek kölcsönös kizárását kell biztosítani.
        
    % critical section
    Ezek a problémák megoldhatóak akkor, ha biztosítható az ágensek számára a kritikus szakaszok egy időben kizárólagos végrehajtása, azaz egy adott szakaszban egyszerre csak egy ágens tartózkodhat. Kritikus szakasz elméleti vázlata a következő lehet: Minden szakasz jellemzője egy zár, amit az ágensek bezárhatnak, kinyithatnak és ellenőrizhetik az állapotát. Ekkor a kritikusz szakasz végrehajtása a következő:
        
    \begin{enumerate}
        \item Az ágens ellenőrzi, hogy a zár nyitva van-e. Ha nem, vár, majd újra próbálkozik.
        \item Ha nyitva találta a zárat, bezárja azt, ezzel jelezve belépését a kritikus szakaszba.
        \item Végrehatja a védendő utasításokat.
        \item Feloldja a zárat, ezzel kilépve a kritikus szakaszból, engedélyezve más ágensek számára a belépést.
    \end{enumerate}
%
    A továbbiakban tekintsünk egy folyamatot, mint konkurens rendszert, amelyben az ütemezett szálak az ágensek. A következő megállapítások általánosíthatóak elosztott rendszerekre. A fenti lépéssorozat naív (és így hibás) implementációja a következő:
    
    \includecpp{criticalsec-wrong}{3}{23}
        
    A fenti megoldás hibája, hogy amennyiben a \texttt{startCritical} metódust végrehajtó szál a \texttt{while} ciklusból való kilépés után elveszti a futási jogát, egy másik szál vele párhuzamosan zárolhatja ugyan azt a zárat, így amikor az előbbi szál újra ütemezésre kerül, egyszerre többen tartózkodhatnak azonos kritikus szakaszban. Valódi párhuzamosságot támogató architektúrán a hibás működés az ütemezéstől függetlenül is előfordulhat, ennek esélyét pedig a különböző végrehajtási egységek dedikált gyorsítótára csak növeli. A probléma felmerülhet egészen egyszerű beágyazott rendszerek esetén is, ahol a végrehajtás szigorúan egy szálon történik és csak egy folyamat van ütemezve, mivel megszakítás (\emph{interrupt}) bármelyik pillanatban érkezhet, így előidézheti a fent leírt jelenséget. Egyes egyszerű példákban megoldás lehet a megszakítások teljes letiltása, az esetek többségében azonban robosztusabb megoldásra van szükség.
    
    A probléma érdekessége, hogy a megoldáshoz hardware oldali támogatás elengedhetetlen. Mivel a zár ellenőrzését és zárolását atomi módon kell megtenni, szükség van arra, hogy az architektúra utasításkészlete ezt egy atomi utasítás formájában megvalósítsa. Ilyen utasítás lehet a \texttt{TSL} (\emph{Test and Set Lock}) vagy a \texttt{CAS} (\emph{Compare And Exchange}). Előbbi az egyik operandusának értékét a másik operandus által mutatott helyre írja, miután a felülírandó értéket egy maghatározott helyre mentette. A viselkedés felhasználható tevékeny várakozás megvalósítására: a zárolást végrehajtó ágens addig próbálja a zárt állapotnak megfelelő értéket a zár által mutatott címre írni, amíg az előző állapot nyitottnak nem adódik -- ekkor biztos lehet benne, hogy a zár az ellenőrzés pillanatában nyitva volt és azonos pillanatban (utasításban) általa zárolásra került.
    
    % CAS
    A \texttt{CAS} utasítás -- megvalósítástól függően -- összehasonlítja egyik operandusát egy regiszter értékével és azt egyezés esetén felülírja a másik operandussal. Amennyiben az összehasonlítás különbséget mutat, az első operandust érintetlenül hagyja és a sikertelenséget jelzi, például a \emph{zero flag} törlésével\footnote{http://courses.engr.illinois.edu/ECE390/archive/spr2002/books/labmanual/inst-ref-cmpxchg.html}. A megközelítés előnye, hogy versengés esetén nem történik memória írás, így elkerülhető a felesleges szinkronizáció. Napjaink konkurenciát támogató megoldásainak többsége a \texttt{CAS} utasításon alapul és minden jelentős platformon támogatott \cite{DiceEtAl}, a korábbi hibás konstrukciónak egy javított változata \texttt{CAS} használatával a következő lehet:
    
    \includecpp{criticalsec-cas}{6}{15}
    
    A \texttt{compare\_exchange\_weak} metódus első argumentumát hasonlítja össze az atomi objektum értékével, egyezés esetén azt a második paraméter értékével írja felül. Az összehasonlítás eredményét visszatérési értékével jelzi. Az atomi utasításokon alapulú konkurenciát támogató struktúrák az \ref{seq:lockfree} szakaszban kerülnek ismertetésre.
    
    A fenti, tevékeny várakozáson alapuló kritikus szakasz (\emph{spinlock}) megoldja a kölcsönös kizárás problémáját, de funkcionalitása nem teljes és teljesítménye sem minden esetben kielégítő. Egy zárral szemben támasztott funkcionális igény lehet az időkorláttal várakozás (\emph{timed wait}) vagy a védett erőforrás írásának és olvasásának a megkülönböztetése (\emph{read-write lock}). A tevékeny várakozás több teljesítményt is érintő problémát okoz:
    
    \begin{itemize} 
        \item A várakozó szál feleslegesen sok CPU ciklust veszteget el, miközben a zár állapotát ellenőrzi gyors ismétlésekben. Egy rosszul megválasztott várakozási idő -- ami a felesleges utasítások számát csökkentené -- súlyosan degradálhatja a rendszer teljesítményét a lassú zár átadás miatt.
        \item Nem biztosítható, hogy a magasabb prioritású szálak előbb hozzájutnak az igényelt erőforrásokhoz.
        \item Egyes szálak -- akár véletlen folytán, különösen alacsony prioritás esetén -- éhezhetnek.
        \item Prioritás öröklés hiányában prioritás inverzió alakulhat ki.
    \end{itemize}
%
    Mivel a fenti problémák alkalmazás-szintű megoldása nagyon körülményes, a modern operációs rendszerek biztosítanak szinkronizációs primitíveket, amelyek kialakítása figyelembe veszi a fenti igényeket és kezeli az ütemezési problémákat. Ezek gyűjtőneve \emph{mutex}, a kölcsönös kizárás (\emph{mutual exclusion}) szavakból ferdítve. Ezen primitívek zárolásának vázlata a következő:
    
    \begin{enumerate}
        \item A szál zárolni próbálja az adott mutexet, ezzel kiváltva egy rendszerhívást
        \item Az operációs rendszer ellenőrzi a mutex állapotát
        \item Amennyiben az szabad, zárolja azt a hívó fél számára, és visszatér
        \item Amennyiben a mutex foglalt, a hívó szálat hozzáadja a mutex várakozási sorához és felfüggeszti a szál futását
    \end{enumerate}
%    
    A felszabadítás vázlata:
    
    \begin{enumerate}
        \item A szál elengedi az adott mutexet, ezzel kiváltva egy rendszerhívást
        \item Az operációs rendszer -- a zár birtokosának ellenőrzése után -- felszabadítja azt
        \item Az operációs rendszer felébreszti a várakozási sorban található szálak egy részhalmazát majd visszatér
    \end{enumerate}
%
    A mutex várakozási listájának modellezése a teljesítményt érintő fontos kérdés. Ha egy egyszerű listát alkalmazunk, elkerüljük az éhezést, de konvoj hatás alakulhat ki -- a rendszer a leglassabb szál sebességével fog haladni, figyelmen kívül hagyva a prioritásokat. Ha prioritási sort alkalmazunk (pl.: kupac), pont fordított lesz a helyzet: érvényesül a szálak prioritása, de éhezés fenyegeti az alacsonyabb prioritású szálakat. Ebben a helyzetben a prioritások adaptív emelése segíthet.
    
    Hasonlóan fontos kérdés a várakozási sorban található szálak felébresztendő részhalmazának kiválasztása. Ha csak egy szálat ébreszt fel a rendszer, (más optimalizációk jelenléte mellett) megnövekszik a kontextusváltások száma az ellentétes esethez képest, amikor a rendszer minden várakozó szálat felébreszt. Ekkor a tomboló csorda (\emph{thundering herd}) probléma jelenthet problémát: egyszerre túl sok szál szeretne a felszabadult erőforráshoz hozzáférni, mivel ez nem sikerül, újra felfüggesztésre kerülnek, ezzel szaggatottá téve a rendszer működését (\emph{thrashing}). A választás megfelelő lehet akkor, ha várható, hogy a mutexet elsőként megszerző szál még a következő preempció előtt az fel is szabadítja, így elkerülve a többi szál újbóli felfüggesztését. Az optimális választás függvénye az ütemező egyéb jellemzőinek.
    
    % futex
    A fenti vázlatszerű megoldásban minden művelet rendszerhívást igényelt. A Linux kernel \emph{futex} (\emph{Fast userspace mutex}) struktúrája elkerüli a rendszerhívások szükségességét, amennyiben nincsenek versenyző szálak. A megoldás alapja egy megosztott memóriaterületre helyezett \emph{futex}, amit bizonyos feltételek mellett az egyes folyamatok maguk zárolhatnak. A megosztott memóriának köszönhetően lehetőség nyílik nem csak szálak, hanem folyamatok szinkronizációjára is \cite{Futex}.
    
    % .net Monitor.Enter
    Hasonló megoldást alkalmaz a Microsoft .NET Framework \emph{Monitor.Enter} metódusa. Amennyiben a monitort üresen találja, belépteti a szálat és zárolja azt, rendszerhívás nélkül, \texttt{CAS} utasítással. Ha zárva találta a monitort vagy nem sikerült a zárolás, először megpróbálkozik egy rövid tevékeny várakozással, elkerülve így a szál felfüggesztését. Ha az időzített \emph{spinning} is sikertelen, a szál a várakozási sorba kerül.\footnote{A működés a http://www.microsoft.com/en-us/download/details.aspx?id=4917 címről letölthető SSCLI 2.0 csomagban, a \texttt{clr/src/vm/syncblk.cpp} fájlban figyelhető meg, az \texttt{AwareLock::Enter} metódustól indulva}
        
    \subsection{Rendszer holtpontja} 
      
    A következőkben tekinktsünk egy rendszerre, mint különböző feladatokat végrehajtó ágensek halmazára. Egy ágens eseményekre vár és bizonyos események hatására műveleteket végez, majd eseményeket vált ki. Ekkor egy rendszer valamely $H$ részhalmaza holtponton van akkor, ha $H$ minden eleme olyan eseményre vár, amit csak $H$ egy másik eleme tud kiváltani. Ha a rendszer bármely részhalmaza holtpontra jut, az adott rész működése leáll, gyakran magával vonva a teljes rendszer használhatatlanná válását. A fenti definícióra egy szemléletes példa a \cite{DiningPhilosophers} probléma, mely röviden a következő képpen vázolható: Egy terített asztal körül filozófusok ülnek. A teríték különlegessége, hogy mindegyikük között csak pontosan egy evőeszköz található, azonban az étkezés megkezdéséhez két evőeszközre van szükségük. Ekkor ha mindegyikük először a jobb oldali evőeszközt veszi kézbe, a bal oldali felvétele előtt várakozásra kényszerül, mivel az bal szomszédjának jobb oldali evőeszköze volt, tehát éppen használatban van. Így kölcsönös egymásra várás alakul ki, tehát az étkezőasztal, mint rendszer, holtpontra jut.
    
    Holtpont előfordulhat a tárgyalt paralell rendszerek esetében is. Ekkor a rendszer (az étkezőasztal) egy futó folyamat, a végrehajtó ágensek (a filozófusok) pedig a folyamat szálai. A definíció és a továbbiakban tárgyalt problémak és megoldások ugyanígy kiterjeszthetőek nagyobb léptékű problémákra is, például elosztott rendszerekre, ahol a rendszer a teljes fürtnek, a végrehajtó ágensek pedig az egyes fürtbe kapcsolt számítógépeknek felelnek meg.
    
    Egy szoftverrendszer számára a holtpont nem szükségszerűen okoz hibás kimenetet, többnyire inkább a kimenet hiánya az elsődleges tünet, ami a működés lebénulását jelenti, anélkül, hogy a holtpontra jutott folyamat terminálna, ezáltal jelezve a hibát az esetleges felügyeleti rendszereknek.
    
    Egy rendszer holtpontmentességének bizonyítása pusztán tesztesetek ismételt futtatásával nem lehetséges. Mivel holtpontot okozhat időzítési probléma (\emph{versenyhelyzet}), gyakran előfordul, hogy fejlesztés közben -- például a hiányzó fordítási idejű optimalizációk miatt -- a probléma nem jelentkezik. Ugyanígy befolyásolhatja az egyes szálak ütemezését, és így a holtpont kialakulásának lehetőségét, egy (az éles környezettől különböző) tesztkörnyezet, a valóditól eltérő tesztadat, vagy pusztán mérési zaj. Ennek ellenére minden erőfeszítést meg kell tenni, hogy a lehetséges problémák még az üzemi környezetbe helyezés előtt kiderüljenek. Egy olyan környezetben, ahol nem áll rendelkezésünkre elegendő hibakeresési eszköz (pl.: \emph{debug szimbólumok}, kimerítő naplóbejegyzések) vagy maga a futó folyamat (csak \emph{post-mortem} vizsgálat lehetséges), ott bekövetkezett holtpont felderítése különösen nehéz.
    
    Adódik a kérdés, hogy hogyan védekezzünk a holtpontok ellen, hogyan elimináljuk a vizsgálat során a nemdeterminisztikusságból adódó bizonytalanságot, milyen technikák léteznek holtpontmentes rendszer kialakítására, valamint hogyan tegyük a rendszerünket ellenállóvá, ha holtpont előfordulhat. A következőkben tárgyalásra kerülnek különböző holtpont megelőzési (\ref{sec:dl-prevention}. szakasz) és holtpont elkerülési (\ref{sec:dl-avoiding}. szakasz) technikák, valamint a \ref{sec:dlhunter}. fejezet bemutat egy ezektől eltérő felderítési technikát alkalmazó eszközt.

%----------------------------------------------------------------------------
\section{Holtpontmegelőzés a gyakorlatban} 
%----------------------------------------------------------------------------
\label{sec:dl-prevention}
%Néhány megelőzési technika bemutatása, hogy később világosan látszódjon, esetünkben miért nem használhattuk ezeket.
    Egy rendszerben holtpont kialakulásának \emph{szükséges} feltételei többek között a következőek:
    
    \begin{description}
    \item[Erőforráselvétel hiánya:] Egy ágens nem foszthat meg egy másikat erőforrásaitól. Példánkban a filozófusok nem vehetik ki egymás kezéből az evőeszközöket.
    \item[Kölcsönös egymásravárás:] Egy ágens várhat egy másikra úgy, hogy közben a másik fél (akár áttételesen) rá vár. Példánkban a holtpont bekövetkeztekor minden filozófus a tőle bal oldalira vár.
    \item[Foglalva várakozás:] Egy ágens várakozhat úgy erőforrásra, hogy közben más erőforrást már zárolt. Példánkban egy filozófus várakozhat evőeszközre, miközben már rendelkezik eggyel.
    \item[Kölcsönös kizárás:] Egyes erőforrásokat egyszerre csak korlátozott számú ágens használhat. Példánkban egy evőeszközt egyszerre csak egy filozófus vehet kézbe.
    \end{description}
%    
    Szükséges feltételek lévén, mindegyiknek egyszerre teljesülnie kell, hogy egy rendszerben felmerüljön a holtpont lehetősége. Holtpont megelőzésnek nevezzük azt, ha egy rendszer úgy kerül kivitelezésre, hogy valamely fenti feltétel semmiképpen sem állhasson fenn. Az ilyen megoldások megvalósítását többnyire tervezési időben el kell határozni, és a rendszerfejlesztés minden szintjén figyelembe kell venni.
    
    Egyes feltételek kizárása különösen sok erőfeszítést igényel. Az erőforráselvétel alapja, hogy az egyes ágenseket prioritizáljuk. Amikor egy ágens zárolna egy mutexet, amit egy alacsonyabb prioritású ágens tart éppen, akkor a zár a magasabb prioritású ágens tulajdonába kerül, az alacsonyabb prioritású pedig visszaáll abba a helyzetbe, amiben a zár megszerzése előtt volt, és várakozni kezd. A zár \emph{átigazolása} az egyszerűbb feladat, az állapotvisszaállítás ellenben komoly problémákat vet fel. Ha a megváltoztatott memóriaterületek nem kerülnek visszaállításra, a rendszer inkonzisztens állapotban maradhat. Ennek érdekében minden zárolás esetén pillanatképet kell készíteni, akár a teljes memóriáról, felkészülve egy esetleges visszaállításra. További problémákat vet fel a kimeneti/bemeneti műveletek visszaállítása, amelyeknek a hatása már kikerülhetett a rendszer hatásköre alól a visszaállítás igényének megjelenésekor, így ezeket késleltetni (kimenet esetén) vagy menteni (bemenet esetén) kell.
    
    Más feltételek megszüntetése valamivel kevesebb komplikációt ígérő technikákkal is megvalósítható. A kölcsönös egymásravárást az \ref{seq:hierarchical} szakasz, a foglalva várakozást az \ref{seq:onsestep} szakasz valamint a kölcsönös kizárást az \ref{seq:lockfree} szakasz tárgyalja.
    % TODO token based message passing?
    % TODO szakaszok igazitasa e szerint


    \subsection{Hierarchikus zárolás} 
    \label{seq:hierarchical}
    A holtpont definíciót megvizsgálva láthatjuk, hogy holtpont akkor fordulhat elő, ha az egyik végrehajtó egység lefoglalt egy erőforráshalmazt, majd ezután egy másikat szeretne kisajátítani, miközben azt már egy másik végrehajtó egység lefoglalta, ami az előbbi halmaz egy elemére vár. Ez megegyezik azzal az esettel, ha a szálak a kérdéses erőforrások halmazának bármely két elemét \emph{különböző sorrendben} zárolnák. A felismerés alapján adódik a hierarchikus zárolás technikájának ötlete: Definiáljunk az erőforrások halmazán egy teljes rendezést. A szálak csak a definiált sorrend szerint növekvő sorrendben zárolhatják az egyes entitásokat, a holtpont kialakulását elkerülendő. 
    
    Ha sikerül a két feltételt betartani, biztosak lehetünk abban, hogy a vizsgált erőforrásokat használó szálak között nem fog holtpont kialakulni. Az entitások rendezéséhez célszerű lenne, ha mindegyikhez egy számértéket rendelnénk, ami alapján egyértelműen adódna a sorrend. Ha a memóriacímet használjuk erre a célra, matematikai értelemben megfelelő rendezést kapunk, azonban ez a sorrend fordításról fordításra (különböző architektúrákon, operációs rendszereken, eltérő fordító kapcsolók esetén vagy pusztán a kód megváltoztatása miatt), valamint futtatásról futtatásra változhat (ASLR\footnote{http://en.wikipedia.org/wiki/Address\_space\_layout\_randomization}-t használó futtatókörnyezet esetén vagy ha a memória nincs virtualizálva). A memóriacím változó jellege miatt nagyon körülményes visszakozó megoldásokat kell alkalmazni az erőforrások zárolása során, melyek erőforráspazarlóak (a sorozatos visszalépések és újrapróbálkozások miatt) vagy nagyon bonyolult struktúrákhoz vezetnek (előre meg kell határozni az erőforrások lefoglalásának sorrendjét és ehez igazítani a műveletek sorrendjét is) melyek rendszerint nem is alkalmazhatóak és karbantartásuk nagyon költséges.
    
    Memóriacímek helyett adjunk manuálisan sorszámot az egyes erőforrásoknak. Ez rendszerint egy tagváltozó beállításával történik, de bizonyos szigorú követelmények mellett (zárak csak globális változók vagy amennyiben tagváltozók, a befoglaló osztályból csak egy példány lehet, mindegyik egy fordítási egységben vagy fájlban van definiálva) használhatunk preprocesszor makrókat, pl.: \texttt{\_\_LINE\_\_} vagy \mbox{BOOST\_PP\_COUNTER()}\footnote{http://www.boost.org/doc/libs/1\_54\_0/libs/preprocessor/doc/ref/counter.html}. A \cite{C++11/Lockable} modellt kiterjesztő beszámozható erőforrásburkoló a következőképpen nézhet ki:
    
    \includecpp{hierarchical-locking}{6}{36}
    
    A fenti példa két problémára is megoldást nyújt: lehetőséget ad az egyes entitások beszámozására az inicializáláskor, valamint biztosítja azt, hogy az egyes szálak csak a legutóbb zárolt de még nem elengedett erőforrás azonosítójánál nagyobb azonosítójú erőforrást zárolhassanak. Az ellenőrző rutin által dobott kivételt nem ajánlott elkapni, a hibát kiváltó szál működését kell a kialakított sorrendhez alakítani. Az ellenőrzés helyes működéséhez szükség van egy szálspecifikus tárolóban elhelyezett veremre, ami a foglalások sorrendjét jegyzi. Fontos megjegyezni, hogy a \texttt{thread\_local} tárolási osztály leíró (\emph{Storage class specifier}) és a benne tárolt nem \cite{C++11/POD}-típusú elemek jelenleg gyengén támogatottak, így egyes platformokon (pl.: GCC version < 4.8) szükséges lehet \texttt{thread\_local} helyett a \texttt{\_\_thread} leíró használata, vagy a verem helyett csak egy veremre mutató pointer tárolása, amit az egyes szálak indításakor inicializálni kell.
    
    A megoldás hátránya, hogy az egyes erőforrásokat már tervezési időben rendezni kell (legalább valamilyen fa struktúrába), hogy az egyes szálak működése ennek megfelelően legyen kialakítva. Ha a sorrend meghatározása a fejlesztés megfelelően korai fázisában elmarad, később csak komoly erőfeszítések árán pótolható, mivel az egyes szálak működésének megváltoztatását vonhatja maga után. 
    
    A másik probléma egy elemenként zárolható listával modellezhető. Tegyük fel, hogy az egyik algoritmusunk a listát balról jobbra tudja hatékonyan feldolgozni, az egyedi elemeket folyamatosan, egymás után zárolva, de nem elengedve, míg egy másik algoritmus ugyan ezt tudja, csak jobbról balra. Ha az elemekhez rendelt zárakat a nekik megfelelő sorban szeretnénk lefoglalni, az egyik algoritmus úgy kell megváltoztatni, hogy az az összes elemet egyszerre (vagy legalábbis igényeihez képest ellentétes irányban) zárolja, ami rontja a hatékonyságát. Ha nem szeretnénk egyik algoritmust sem megváltoztatni, használhatunk egy lista szintű zárat, ez viszont csökkenti a zárolás granualitását, ami adott esetben kritikus lehet.
    
    Az elemenként zárolható lista példája életszerűtlennek tűnhet, viszont az ezzel modellezhető problémák (pl.: üzenet propagálása egy architektúra rétegein keresztül) nagyonis életszerűek.
    
    A hierarchikus zárolás technika alkalmazása olyan feladatokban, ahol az adatfolyam iránya egyértelmű, sikerrel használható, de különös körültekintést és alapos tervezést igényel, ellenben a fent bemutatott példának a futásidejű többletterhelése nem szignifikáns. Ezzel szemben már létező, karbantartandó, a technikát nem alkalmazó problémás alkalmazások ilyen módú kijavítása ritkán vezet eredményre és komoy erőfeszítést igényel. Olyan feladatok esetén, ahol az egyes komponensek kommunikációjának iránya nem egyértelmű, a technika nem alkalmazható jelentős teljesítménybeli degradáció nélkül.
    
    \subsection{Egylépéses zárolás}
    \label{seq:onsestep}
    
    A holtpont megelőzhető úgy, ha minden szál a szükséges erőforrásokat egy lépésben foglalja le. Ennek menete a következő: A szál meghatározza a zárolandó entitásokat, majd sorban megpróbálja őket lefoglalni. Amennyiben valamelyik erőforrás foglalt, az összes többit elengedi, majd várakozni kezd a foglalt entitásra. A C++11 \texttt{std::lock()} metódusa is ezt a működést valósítja meg \cite{C++11/lock}:
    
    \includecpp{stdlock}{11}{19}
%    
    A fenti megoldás hibája, ha a {lock()} hívás után bármelyik művelet kivételt eredményez, a mutexek zárva maradnak. Java vagy C\texttt{\#} környezetben bevett szokás a probléma megoldására egy \texttt{try-finally} blokkot vonni a védett operációk köré, és a \texttt{finally} blokkban végezni az erőforrások felszabadítását. C++ esetében a preferált megoldás a \texttt{RAII} idiom \cite{ExceptionalC++} alkalmazása.
    
    \includecpp{stdlock}{23}{31}
%    
    A \texttt{lock\_guard} burkoló osztályok gondoskodnak arról, hogy megsemmisülésükkor elengedjék a felügyelt mutexet. Mivel kivétel keletkezése esetén a vezérlés elhagyja a kapcsos zárójelek által határolt blokkot, meghívódik az őr példányok destruktora és a fenti működés érvényre jut, biztosítva ezzel az inkonzisztens állapot kialakulásának megakadályozását. A \texttt{lock\_guard} konstruktora alapértelmezett esetben megpróbálja a felügyelt erőforrást zárolni, a \texttt{std::adopt\_lock} címke feltüntetésével jelezzük, hogy erre már nincs szükség.
    
    Megjegyzendő, hogy a fenti technikák nem csak a standard könyvtár mutex típusával működnek, hanem bármilyen más típussal, ami kielégíti a \texttt{Lockable} modell követelményeit \cite{C++11/Lockable}. A megvalósítandó metódusok rövid leírásukkal a következőek:
    
\begin{description}
    \item[\texttt{lock()}:] Blokkol addig, amíg nem tudja zárolni az erőforrást. Amennyiben kivétel keletkezik, az erőforrás nem marad zárolva.
    \item[\texttt{unlock()}:] Felszabadítja az erőforrást, kivételt nem válthat ki.
    \item[\texttt{try\_lock()}:] Blokkolás nélkül megkísérli zárolni az erőforrást, a sikerességet visszatérési értékével jelzi.
\end{description}
%
    A fentiek figyelembe vételével könnyen készíthetünk olyan burkoló osztályokat, amelyek a standard könyvtár zárolást támogató eszközeivel együttműködve használható és olyan erőforrásokat felügyel, amelyek alapértelmezetten nem támogatják a párhuzamos hozzáférést (pl.: adatbázis-kapcsolat, hálózati leíró).
    
    A bemutatott megoldás megelőzi a holtpontot kialakulását, mivel a \texttt{std::lock()} hívást végrehajtó szál ahelyett, hogy más erőforrásokat zárolva tartva várakozna, a sikeresen kisajátított zárakat először elengedi, és utána kezdi meg a várakozást, így nem alakulhat ki egymásra várás, mivel ha valaki várakozik, akkor nem birtokol erőforrásokat.
    
    Holtpont helyett viszont más problémák merülnek fel: a leírt visszakozás, \emph{backoff} stratégia alkalmazása során fenyeget a \emph{livelock} kialakulásának veszélye: a végrehajtó egységek nagyon udvariasan újra és újra elengedik a már lefoglalt erőforrásokat, érdemi előrelépés nélkül. A gyorsan ismétlődő visszakozásokból adódóan a \emph{livelock} szituációk súlyosan degradálják a rendszer teljesítményét.
    
    A megoldás másik hátránya a zárolási granualitás problémája. Ha több, egymásra épülő műveletet szeretnénk végrehajtani, hagyományos esetben a későbbi műveletek által igényelt erőforrások kisajátítását későbbre halaszthatjuk, így növelve a multiprogramozás fokát és a rendszer teljesítményét. Egylépéses zárolás esetén kénytelenek vagyunk minden entitást előre lefoglalni, így feleslegesen hosszú időre (túl korán) kisajátítani azokat, kizárva annak a lehetőségét, hogy más szálak azokon műveleteket végezhessenek, amikor ezt a végrehajtott műveletsor nem indokolja. Különösen rossz a helyzet akkor, ha (egy másik foglalás mellett) zárolható entitások listáján kell műveletet végeznünk: ahelyett, hogy csak az aktuális elemet sajátítanánk ki, kénytelenek vagyunk a teljes lista összes elemét zárolnunk, feleslegessé téve ezzel az elemszintű mutexeket, a konkurencia szintjét gyakorlatilag nullára csökkentve.
    
    További problémája a technikának, ha a lefoglalandó erőforrások egy részét csak futási időben ismerjük meg, egy másik zárolandó entitással történő interakció után. Ilyenkor csak nagyon körülményesen, vagy akár (csak futásidőben ismert számú erőforrás esetén) sehogyan sem tudjuk alkalmazni a megoldást.
    
    Az egylépéses zárolás megfelelő lehet kisebb alkalmazások holtpontmentességének biztosítására, nagyobb rendszerek esetén azonban a teljesítményt komoly mértékben negatívan befolyásoló jellege miatt nem megfelelő eszköz.
    
    \subsection{Lock-free adatstruktúrák \textcolor{red}{TODO}}
    \label{seq:lockfree}
     AFAIK aktív kutatási terület, akár egy fél doktorit is lehetne ide írni. ABA
     % http://msdn.microsoft.com/en-us/library/system.collections.concurrent.aspx
    \subsection{Token alapú adathozzáférés \textcolor{red}{TODO}} Shared data atomic pointere swappelődik a threadek között.

%----------------------------------------------------------------------------
\section{Holtpontdetektálás a gyakorlatban \textcolor{red}{TODO}} 
\label{sec:dl-avoiding}
Ha megelőzni nem tudtuk, hogyan gyomláljuk ki
%----------------------------------------------------------------------------
    \subsection{Zárak nyilvántartása} DB rendszerek holtpont detektorai
    \subsection{Tünetvizsgálat \textcolor{red}{TODO}} CPU usage, progress monitorozása
    \subsection{Intel® Parallel Studio XE 2013 \textcolor{red}{TODO}} http://software.intel.com/en-us/intel-parallel-inspector Sajnos nincs trial, nem világos, hogy pontosan mit csinál a háttérben
    
%----------------------------------------------------------------------------
\section{Összegzés \textcolor{red}{TODO}} 
Fentiek előnye hátránya, mikor használható/mikor nem, amikor nem, akkor mi? -> chapter 2.
%----------------------------------------------------------------------------
